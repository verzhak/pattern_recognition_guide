
Ключевой компонентой программного комплекса, осуществляющего распознавание образов, является модуль принятия решений об отнесении того или иного образа к тому или иному объекту или к помехе. Означенный модуль может быть организован с помощью классификатора, обучаемого с учителем.

Классификаторы, обучаемые с учителем, в общем случае решают задачу построения регрессии $y = f(x) ;~ x = \{ x_1, x_2, ..., x_{N_x} \} ;~ y = \{ y_1, y_2, ..., y_{N_y} \} ;~ x_i, y_j \in \mathbb{R} ;~ i = \overline{1, N_x} ;~ j = \overline{1, N_y}$, где:

\begin{itemize}

	\item $x$ - вектор признаков образа;
	\item $y$ - вектор зависимых переменных (в задачах классификации - номера классов, вероятности отнесения образа к классам и тому подобное).

\end{itemize}

Различные классификаторы, обучаемые с учителем, выполняют разбиение векторного пространства $X = \{ x \}$ на классы различными способами - однако, всегда таковое разбиение выполняется по обучающему множеству векторов $T_{teach} = \{ <x_1, y_1>, <x_2, y_2>, ...,  <x_{N_{teach}}, y_{N_{teach}}>  \}$ - множеству заранее классифицированных векторов $x$. Качество выполненного обучения проверяется на тестовом множестве векторов $T_{test} = \{ <x_{test}, y_{test}> \}$ - множестве заранее классифицированных векторов $x$ таком, что $T_{teach} \cap T_{test} = \varnothing$.

Простые классификаторы могут быть объединены в составные классификаторы, содержащие функциональные блоки комбинирования выходов отдельных классификаторов (например, несколько классификаторов, значения на выходах которых суть есть вероятности принадлежности образа к каждому из существующих классов, могут быть объединены в составной классификатор, выходом которого будет номер класса, вероятность принадлежности образа к которому максимальна).

Теория машинного обучения ((англ.) machine learning; ml) занимается разработкой способов построения классификаторов, обучаемых с учителем. К таковым способам относятся следующие концепции:

\begin{itemize}

	\item многослойный перцептрон;
	\item машина опорных векторов;
	\item наивный Баесовский классификатор;
	\item дерево решений;
	\item алгоритм ближайших соседей;
	\item регрессия, рассчитываемая методом наименьших квадратов.

\end{itemize}

\myparagraph{Многослойный перцептрон}

Многослойный перцептрон ((англ.) Multi Layer Perceptron; MLP) является искусственной нейронной сетью, обучаемой с учителем.

Частный случай многослойного перцептрона - однослойный перцептрон - впервые был предложен Ф. Розенблаттом в 1957-м году в попытке моделировать мозговую деятельность человека. Розенблатт и ряд других авторов справедливо полагали, что человеческий мозг, являясь лучшим из существующих механизмов классификации образов, концептуально может послужить основой для оптимальных, с точки зрения человеческого восприятия, классификаторов.

В общем случае, многослойный перцептрон выполняет построение регрессии $y = mlp(x)$, однако, чаще всего, перцептрон применяется для решения задач классификации как самостоятельный классификатор (выдающий на свой выход вероятность отнесения вектора $x$ к целевому классу или вектор вероятностей отнесения вектора $x$ ко всем имеющимся классам - второй случай, однако, менее эффективен, так как требует от перцептрона построения всего набора гиперплоскостей, разделяющих классы), так и в составе сложного классификатора.

Структурная схема многослойного перцептрона приведена на рисунке \ref{image:pr:2:mlp}.

\mimagebegin{pr:2:mlp}{Структурная схема многослойного перцептрона}
\noindent
\begin{tikzpicture}[]

	\tikzstyle {ttt} = [circle, minimum width = 1.2cm, text centered, line width = 1pt, node distance = 1.9cm];
	\tikzstyle {neuro} = [ttt, draw];
	\tikzstyle {neuroS} = [ttt, draw, fill = red];
	\tikzstyle {neuroH} = [ttt, draw, fill = green!70!black];
	\tikzstyle {neuroR} = [ttt, draw, fill = blue];
	\tikzstyle {mpath} = [->, very thick, line width = 2pt];
	\tikzstyle {lbl} = [text centered, text width = 15em, node distance = 1.5cm];

	\node [ttt] (X1) {\Large $\bf x_1$};
	\node [ttt, below of = X1] (Xttt) {...};
	\node [ttt, below of = Xttt] (XQ) {\Large $\bf x_{N_x}$};

	\node [ttt, right of = Xttt] (Sttt) {...};
	\node [neuroS, above of = Sttt] (S2) {2};
	\node [neuroS, above of = S2] (S1) {1};
	\node [ttt, below of = Sttt] (SN1) {...};
	\node [neuroS, below of = SN1] (SN) {$N_S$};

	\node [ttt, right of = Sttt, node distance = 4cm] (Fttt) {...};
	\node [ttt, below of = Fttt] (FN2) {...};
	\node [ttt, below of = FN2] (FN1) {...};
	\node [neuroH, below of = FN1] (FN) {$N_1$};
	\node [neuroH, above of = Fttt] (F3) {3};
	\node [neuroH, above of = F3] (F2) {2};
	\node [neuroH, above of = F2] (F1) {1};

	\node [ttt, right of = Fttt] (Tttt) {...};
	\node [ttt, above of = Tttt] (Tttta1) {...};
	\node [ttt, above of = Tttta1] {...};
	\node [ttt, below of = Tttt] (Ttttb1) {...};
	\node [ttt, below of = Ttttb1] {...};

	\node [ttt, right of = Tttt] (Lttt) {...};
	\node [neuroH, above of = Lttt] (L2) {2};
	\node [neuroH, above of = L2] (L1) {1};
	\node [ttt, below of = Lttt] (LN1) {...};
	\node [neuroH, below of = LN1] (LN) {$N_M$};

	\node [ttt, right of = Lttt, node distance = 4cm] (Rttt) {...};
	\node [neuroR, above of = Rttt] (R1) {1};
	\node [neuroR, below of = Rttt] (RN) {$N_{N_y}$};

	\node [ttt, right of = Rttt] (Yttt) {...};
	\node [ttt, below of = Yttt] (YQ) {\Large $\bf y_{N_y}$};
	\node [ttt, above of = Yttt] (Y1) {\Large $\bf y_1$};

	\node [lbl, color = red, below of = SN] {\bf Слой S - нейронов \\ (сенсорные нейроны)};
	\node [lbl, color = green!70!black, above of = L1] {\bf $\bf M$ слоев A - нейронов \\ (ассоциативные нейроны)};
	\node [lbl, color = blue, below of = RN, node distance = 1.7cm] {\bf Слой R - нейронов \\ (реагирующие нейроны)};

	\path (X1) edge [mpath] (S1);
	\path (X1) edge [mpath] (S2);
	\path (X1) edge [mpath] (SN);

	\path (XQ) edge [mpath] (S1);
	\path (XQ) edge [mpath] (S2);
	\path (XQ) edge [mpath] (SN);

	\path (S1) edge [mpath] (F1);
	\path (S1) edge [mpath] (F2);
	\path (S1) edge [mpath] (F3);
	\path (S1) edge [mpath] (FN);

	\path (S2) edge [mpath] (F1);
	\path (S2) edge [mpath] (F2);
	\path (S2) edge [mpath] (F3);
	\path (S2) edge [mpath] (FN);

	\path (SN) edge [mpath] (F1);
	\path (SN) edge [mpath] (F2);
	\path (SN) edge [mpath] (F3);
	\path (SN) edge [mpath] (FN);

	\path (L1) edge [mpath] (R1);
	\path (L1) edge [mpath] (RN);

	\path (L2) edge [mpath] (R1);
	\path (L2) edge [mpath] (RN);

	\path (LN) edge [mpath] (R1);
	\path (LN) edge [mpath] (RN);

	\path (R1) edge [mpath] (Y1);
	\path (RN) edge [mpath] (YQ);

	\path (Fttt) edge [->, very thick, line width = 10pt, color = green!70!black] (Lttt);

\end{tikzpicture}
\mimageend

Входной вектор $x$ подается на нейроны входного слоя нейронов перцептрона (S - слой; сенсорный слой). Нейроны S - слоя транслируют входной вектор на входы первого из скрытых слоев (A - слоев; слоев ассоциативных нейронов). Скрытые нейроны выполняют основной набор вычислений. Нейроны последнего ($M$-го) скрытого слоя передают свои выходы на реагирующие нейроны (нейроны R - слоя), выходы которых формируют выходной вектор $y$ перцептрона.

Каждый из нейронов рассчитывает взвешенную сумму своих входов, применяет к сумме функцию активации и передает результат вычисления функции активации на свой выход. Задача обучения перцептрона состоит в настройке весов нейронов.

На настоящий момент существует ряд алгоритмов обучения перцептрона, среди которых можно выделить следующие:

\begin{itemize}

	\item алгоритмы минимизации квадратичного функционала ошибки $E(T_{teach})$ классификации множества $T_{teach}$:

	\begin{itemize}

		\item алгоритм градиентного спуска (часто называемый алгоритмом обратного распространения ошибки, что не совсем верно - по алгоритму обратного распространения ошибки рассчитывается градиент функционала $E()$, который, впоследствии, и является основной, но не единственной, компонентой корректирующего коэффициента);
		\item метод Ньютона, основанный на использовании информации о значении и структуре второй производной функционала $E()$;
		\item метод Гаусса - Ньютона и различные улучшения данного метода (например, алгоритм Левенберга - Марквардта), основанные, в отличии от метода Ньютона, не на Гессиане функции $E()$, но на приближении Гессиана чем - либо (например, Якобианом);
	
	\end{itemize}

	\item метод сопряженных градиентов, выполняющий построение базиса векторного пространства, в котором лежит вектор весов всех нейронов перцептрона, и дальнейшее построение вектора весов по найденному базису;
	\item генетический алгоритм, выполняющий интелектуальный подбор весов нейронов перцептрона;
	\item различные эвристические алгоритмы (RPROP, QuickPROP и другие).

\end{itemize}

Библиотека OpenCV реализует многослойный перцептрон в виде класса \verb|CvANN_MLP|. Ключевые методы класса \verb|CvANN_MLP| перечислены в листинге \ref{listing:pr:2:mlp}.

\mylistingbegin{pr:2:mlp}{Класс CvANN\_MLP (многослойный перцептрон)}
\begin{lstlisting}

CvANN_MLP
{
	public:
	
		CvANN_MLP();
		CvANN_MLP(Mat layers_size, int activate_func = CvANN_MLP::SIGMOID_SYM, double param1 = 0, double param2 = 0);

		void create(Mat layers_size, int activate_func = CvANN_MLP::SIGMOID_SYM, double param1 = 0, double param2 = 0);
		
		int train(Mat samples, Mat outputs, const Mat & sample_weights);
		
		float predict(Mat vec, Mat & outputs);

};

\end{lstlisting}
\mylistingend

В листинге \ref{listing:pr:2:mlp} приведены прототипы следующих методов класса \verb|CvANN_MLP|:

\begin{itemize}

	\item конструктор \verb|CvANN_MLP()| - создает неинициализированный перцептрон;
	\item конструктор \verb|CvANN_MLP(Mat layers_size, ...)| и метод \verb|create()| - инициализируют перцептрон.

	Перечисленные методы обладают следующими параметрами:

	\begin{itemize}

		\item \verb|layers_size| - матрица, содержащая размеры каждого из слоев перцептрона.
			
		Матрица \verb|layers_size| содержит одну строку и $M + 2$ столбцов. Элементы матрицы являются 32-х битовыми знаковыми целыми (\verb|CV_32SC1|);

		\item \verb|activate_func| - идентификатор функции активации нейронов перцептрона.

		Данный параметр может принимать следующие значения:

		\begin{itemize}

			\item \verb|CvANN_MLP::IDENTITY| - функция идентичности: $y = x$;
			\item \verb|CvANN_MLP::SIGMOID_SYM| - симметричная сигмоида: $y = \beta \dfrac{1 - e^{-\alpha x}}{1 + e^{-\alpha x}} ;~ y \in \mathbb{R} ;~ y \in (-1, 1)$;
			\item \verb|CvANN_MLP::GAUSSIAN| - функция Гаусса: $y = \beta e^{- \alpha x ^ 2}$; % TODO на 13.03.2012 - 2.3.1 - поддерживается не полностью

		\end{itemize}

		\item \verb|param1|, \verb|param2| - соответственно, параметры $\alpha$ и $\beta$ функций активации нейронов перцептрона.

		В случае, если для активации нейронов используется симметричная сигмоида, то при передаче нулей в качестве значений перечисленных параметров значения $\alpha$ и $\beta$ принимаются равными единице;

	\end{itemize}

	\item метод \verb|train()| - обучает перцептрон.

	В случае, если методу \verb|train()| не было передано никаких дополнительных параметров, то обучение перцептрона производится по алгоритму RPROP.

	Параметр \verb|sample_weights| позволяет указать вес (<<значимость>>) каждого из векторов обучающего множества. Передача пустой матрицы (\verb|Mat()|) в качестве значения данного параметра предполагает, что все вектора обучающего множества имеют одинаковый вес;

	\item метод \verb|predict()| - классифицирует входной вектор, записанный в первую и единственную строку матрицы \verb|vec|.

\end{itemize}

Элементы матриц \verb|samples|, \verb|vec|, \verb|outputs| должны быть вещественными одинарной точности (\verb|CV_32FC1|).

\myparagraph{Машина опорных векторов}

Машина опорных векторов ((англ.) Support Vector Machine; SVM) относится к категории нейроподобных структур и является бинарным классификаторов - классификатором, разбивающим векторное пространство $X$ на два класса. Ключевым преимуществом SVM по сравнению с многослойным перцептроном является то, что, в отличии от перцептрона, строящего линейное разбиение $X$, SVM выполняет нелинейное разбиение $X$.

Идея, лежащая в основе машины опорных векторов, состоит в следующем:

\begin{itemize}

	\item машина опорных векторов нелинейным образом проецирует векторное пространство $X$ в векторное пространство $X'$ большей размерности: $X \to X'$;
	\item машина опорных векторов выполняет линейное бинарное разбиение векторного пространства $X'$.

\end{itemize}

Гиперплоскость $L(S, x)$, описывающая разбиение векторного пространства $X'$, определяется уравнением \eqref{pr:2:L}:
\begin{gather}
	L(S, x) = \sum_{i = 1}^{N_S} w_i K(s_i, x) + b \label{pr:2:L} \\
	w_i \in W ;~ s_i \in S ;~ i = \overline{1, N_S} ;~ x \in X ;~ b \in \mathbb{R} \notag,
\end{gather}

где:

\begin{itemize}
			
	\item $S = \{s_1, s_2, ..., s_{N_S}\} ;~ S \subset X$ - множество опорных векторов;
	\item $W = \{w_1, w_2, ..., w_{N_S}\} ;~ W \subset \mathbb{R}$ - вектор коэффициентов при соответствующих опорных векторах;
	\item $b ;~ b \in \mathbb{R}$ - пороговый коэффициент;
	\item $K(s, x) ;~ s \in S ;~ x \in X$ - ядро скалярного произведения образов векторов $s$ и $x$ в пространстве $X'$.

\end{itemize}

Нелинейность однозначного отображения $X \to X'$ достигается, таким образом, за счет функции ядра скалярного произведения $K(s, x)$ векторов пространства $X'$.

В качестве ядра скалярного произведения могут использоваться следующие функции:

\begin{itemize}

	\item однородные полиномы произвольной степени;
	\item неоднородные полиномы произвольной степени;
	\item радиальная базисная функция \eqref{pr:2:f:rbf}:
\begin{gather}
	\label{pr:2:f:rbf}K(s, x) = \exp(-\sigma\|s - x\|^2),
\end{gather}

	где $\sigma ;~ \sigma \in \mathbb{R}$ - некоторая константа;

	\item гиперболический тангенс \eqref{pr:2:f:tanh}:
\begin{gather}
	\label{pr:2:f:tanh} K(s, x) = tanh \left ( A s^T * x + B \right ),
\end{gather}

	где $A, B ;~ A, B \in \mathbb{R}$ - некоторые константы;

	\item пересечение \eqref{pr:2:f:intersection}:
\begin{gather}
	\label{pr:2:f:intersection} K(s, x) = \sum_{i = 1}^{N_x} \min(s_i, x_i).
\end{gather}

\end{itemize}

Задача обучения машины опорных векторов сводится к задаче условной квадратичной оптимизации - необходимо максимизировать функционал \linebreak $Q(T_{teach}, \alpha)$ \eqref{pr:2:Q}, называемый функцией Лагранжа, по набору переменных $\alpha$ при выполнении условий Каруша - Кун - Таккера \eqref{pr:2:Q-cond}:
\begin{gather}
	\label{pr:2:Q}
	Q(T_{teach}, \alpha) = \sum_{i = 1}^{N_{teach}}\alpha_i -
			\dfrac{1}{2} \sum_{i = 1}^{N_{teach}} \sum_{j = 1}^{N_{teach}} \alpha_i \alpha_j d_i d_j K(x_i, x_j) \\
	\label{pr:2:Q-cond}
	\sum_{i = 1}^{N_{teach}} \alpha_i d_i = 0 ;~ 0 \le \alpha_i \le C \\
	d_i = f(y_i) \notag \\
	<x_i, y_i>, <x_j, y_j> ~ \in ~ T_{teach} ;~ \alpha_i, \alpha_j, C \in \mathbb{R} ;~ i, j = \overline{1, N_{teach}}, \notag
\end{gather}

где:
	
\begin{itemize}
			
	\item $\alpha = \{\alpha_1, \alpha_2, ..., \alpha_{N_{teach}}\}$ - вектор множителей Лагранжа;
	\item $d = \{d_1, d_2, ..., d_{N_{teach}}\} ;~ d_i \in \{-1, 1\}$ - вектор, компоненты которого маркируют принадлежность соответствующих векторов из $T_{teach}$ к одному из двух классов, разбиение на которые выполняет SVM;
	\item $f(y)$ - отображение $y \to d$;
	\item $C$ - некоторый коэффициент.

\end{itemize}

Наиболее популярным алгоритмом оптимизации функции Лагранжа $Q(T_{teach}, \alpha)$ является алгоритм (англ.) Sequential Minimal Optimization (SMO) различных версий (например, версии тайваньских ученых: Rong-En Fan, Pai-Hsuen Chen, Chih-Jen Lin).

По завершении выполнения алгоритма SMO по обучающей выборке $T_{teach}$ и вектору множителей Лагранжа $\alpha$ составляется \eqref{pr:2:Sw} множество $S$ опорных векторов, вектор коэффициентов $W$ и рассчитывается значение порогового коэффициента $b$:
\begin{gather}
	\label{pr:2:Sw}
	<x_i, y_i> ~\in~ T_{teach} ;~ \alpha_i \in \alpha ;~ \alpha_i > 0 ~ => ~ x_i \in S \\
	w_j = \alpha_j d_j \notag \\
	b = \dfrac{\sum_{i = 1}^{N_S}(\sum_{j = 1}^{N_S}w_j s_{ij} - d_i)}{N_S}. \notag
\end{gather}

Обычно машины опорных векторов используются не по одиночке, но в составе сложного классификатора, реализующего разбиение векторного пространства $X$ на несколько (больше двух) классов. Библиотека OpenCV реализует такой классификатор в виде класса \verb|CvSVM|. Ключевые методы класса \verb|CvSVM| перечислены в листинге \ref{listing:pr:2:svm}.

\mylistingbegin{pr:2:svm}{Класс CvSVM (классификатор, составленный из нескольких машин опорных векторов)}
\begin{lstlisting}

class CvSVM
{
	public:

		CvSVM();
		CvSVM(Mat samples, Mat responses, Mat(), Mat(), CvSVMParams params = CvSVMParams());

		bool train(Mat samples, Mat responses, Mat(), Mat(), CvSVMParams params = CvSVMParams());

		float predict(Mat vec);
};

\end{lstlisting}
\mylistingend

В листинге \ref{listing:pr:2:svm} приведены прототипы следующих методов класса \verb|CvSVM|:

\begin{itemize}

	\item конструктор \verb|CvSVM()| - создает классификатор;
	\item конструктор \verb|CvSVM(Mat samples, ...)| и метод \verb|train()| - (создают и) обучают классификатор.

	Перечисленные методы обладают следующими параметрами:

	\begin{itemize}

		\item \verb|samples| - матрица, составленная из векторов $x$ из обучающего множества векторов $T_{teach}$ (тип элементов матрицы - вещественное одинарной точности; \verb|CV_32FC1|);
		\item \verb|responses| - матрица, составленная из векторов $y$ из обучающего множества векторов $T_{teach}$ такие, что $N_y = 1 ;~ y \in \mathbb{Z} ;~ y \in [0, W)$, где $W$ - количество классов, на которое выполняется разбиение пространства $X$.

		Таким образом, матрица \verb|responses| состоит из $N_{teach}$ строк, одного столбца и элементов, тип которых суть есть 32-х битовое знаковое целое (\verb|CV_32SC1|);

		\item \verb|params| - набор параметров SVM, входящих в состав классификатора.

		Класс \verb|params| обладает, как минимум, следующими полями:

		\begin{itemize}

			\item \verb|svm_type| - идентификатор типа используемых SVM (может принимать значения констант: \linebreak \verb|CvSVM::C_SVC|, \verb|CvSVM::NU_SVC| и других; для использования SVM, оперирующих коэффициентом $C$ для ограничения сверху диапазона поиска множителей Лагранжа, в качестве идентификатора типа используемых SVM необходимо указать значение константы \verb|CvSVM::C_SVC|);
			\item \verb|C| - значение коэффициента $C$.

			Хорошим значением коэффициента $C$ станет значение из диапазона $(0, 10]$;

			\item \verb|kernel_type| - идентификатор ядра скалярного произведения.
			
			Поле \verb|kernel_type| может принимать следующие значения;
		
			\begin{itemize}
				
				\item \verb|CvSVM::LINEAR| - скалярное произведение векторов;
				\item \verb|CvSVM::POLY| - неоднородный полином произвольной степени.

				Степень полинома может быть указана с помощью поля \verb|degree|. Коэффициент неоднородности может быть задан с помощью поля \verb|coef0|;

				\item \verb|CvSVM::RBF| - радиальная базисная функция.

				Коэффициент $sigma$ может быть задан с помощью поля \verb|gamma|;

				\item \verb|CvSVM::SIGMOID| - сигмоида;

			\end{itemize}

			\item \verb|term_crit| - критерий останова процесса обучения каждой из SVM, входящих в состав классификатора.
			
			В качестве значения поля \verb|term_crit| рекомендуется указывать \linebreak \verb|TermCriteria(CV_TERMCRIT_EPS, (int) 1e7, 1e-6)|;

		\end{itemize}

	\end{itemize}

	\item метод \verb|predict()| - классифицирует вектор, записанный в первую и единственную строку матрицы \verb|vec| (тип элементов матрицы - вещественное одинарной точности; \verb|CV_32FC1|).

	Функция \verb|predict()| возвращает номер класса, к которому отнесен входной вектор. Номер класса, в данном случае, возвращается в виде вещественного числа, которое, впрочем, может быть неявно преобразовано к целому.

\end{itemize}

\myparagraph{Наивный Баесовский классификатор}

Наивный Баесовский классификатор суть есть простой вероятностный классификатор, основанный на теореме Байеса \eqref{pr:2:bayes} со строгими (наивными) предположениями о независимости.
\begin{gather}
	\label{pr:2:bayes}
	P(A | B) = \frac{P(B | A) P(A)}{P(B)},
\end{gather}

где:

\begin{itemize}

	\item $P(A)$ — априорная вероятность гипотезы $A$;
	\item $P(A | B)$ — вероятность гипотезы $A$ при наступлении события $B$ (апостериорная вероятность);
	\item $P(B | A)$ — вероятность наступления события $B$ при истинности гипотезы $A$;
	\item $P(B)$ — вероятность наступления события $B$.

\end{itemize}

Оценка $y$ вероятности принадлежности вектора $x$ к классу $C$ оценивается по формуле \eqref{pr:2:bayes:p}:
\begin{gather}
	\label{pr:2:bayes:p}
	y = P(C | x_1, x_2, ..., x_{N_x}) = \dfrac{1}{Z} P(C) \prod_{i = 1}^{N_x} P(x_i | C),
\end{gather}

где:

\begin{itemize}

	\item $P(C)$ - априорная вероятность принадлежности вектора $x$ к классу $C$;
	\item $P(x_i | C)$ - вероятность того, что вектор, значение $i$-ой компоненты которого равно $x_i$, относится к классу $C$;
	\item $Z$ - масштабный множитель.

\end{itemize}

Задача обучения Баесовского классификатора сводится, таким образом, к оценке вероятностей $P(C)$ и $P(x_i | C)$ для всех классов по обучающему множеству $T_{teach}$ векторов - наивный Баесовский классификатор выполняет в некотором смысле статистически оптимальное разбиение векторного пространства $X$ на целевые классы.

Библиотека OpenCV реализует наивный Баесовский классификатор в виде класса \linebreak \verb|CvNormalBayesClassifier|. Ключевые методы класса \verb|CvNormalBayesClassifier| перечислены в листинге \ref{listing:pr:2:bayes}.

\mylistingbegin{pr:2:bayes}{Класс CvNormalBayesClassifier (наивный Баесовский классификатор)}
\begin{lstlisting}

class CvNormalBayesClassifier
{
	public:

		CvNormalBayesClassifier();

		bool train(Mat samples, Mat responses);

		float predict(Mat vec);
};

\end{lstlisting}
\mylistingend

В листинге \ref{listing:pr:2:bayes} приведены прототипы следующих методов класса \verb|CvNormalBayesClassifier|:

\begin{itemize}

	\item конструктор \verb|CvNormalBayesClassifier()| - создает классификатор;
	\item метод \verb|train()| - обучает классификатор.

	Метод \verb|train()| обладает следующими параметрами:

	\begin{itemize}

		\item \verb|samples| - матрица, составленная из векторов $x$ из обучающего множества векторов $T_{teach}$ (тип элементов матрицы - вещественное одинарной точности; \verb|CV_32FC1|);
		\item \verb|responses| - матрица, составленная из векторов $y$ из обучающего множества векторов $T_{teach}$ таких, что $N_y = 1 ;~ y \in \mathbb{Z} ;~ y \in [0, W]$, где $W$ - количество классов, на которое выполняется разбиение пространства $X$.

		Таким образом, матрица \verb|responses| состоит из $N_{teach}$ строк, одного столбца и элементов, тип которых суть есть 32-х битовое знаковое целое (\verb|CV_32SC1|);

	\end{itemize}

	\item метод \verb|predict()| - классифицирует вектор, записанный в первую и единственную строку матрицы \verb|vec| (тип элементов матрицы - вещественное одинарной точности; \verb|CV_32FC1|).

	Функция \verb|predict()| возвращает номер класса, к которому отнесен входной вектор. Номер класса, в данном случае, возвращается в виде вещественного числа одинарной точности, которое может быть неявно преобразовано к целому.

\end{itemize}

